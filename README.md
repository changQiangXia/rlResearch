# RL_Evolution: From Q-Learning to PPO

<h3 align="center">
  <a href="#chinese">ğŸ‡¨ğŸ‡³ ä¸­æ–‡</a> | 
  <a href="#english">ğŸ‡ºğŸ‡¸ English</a>
</h3>

---

<a name="chinese"></a>
## ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆ

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.13+-red.svg)](https://pytorch.org/)
[![Gym](https://img.shields.io/badge/Gym-0.21+-green.svg)](https://gym.openai.com/)

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ª**ä»é›¶å¼€å§‹å®ç°**çš„å¼ºåŒ–å­¦ä¹ æ•™ç¨‹ï¼Œå®Œæ•´å±•ç¤ºäº†ä»ç®€å•çš„ Q-Learning åˆ°å…ˆè¿›çš„ PPO ç®—æ³•çš„æ¼”è¿›è¿‡ç¨‹ã€‚

### ğŸ¯ é¡¹ç›®ç‰¹è‰²

- **æ¨¡å—åŒ–è®¾è®¡**ï¼šç¯å¢ƒäº¤äº’ã€ç½‘ç»œæ¨¡å‹ã€ç¼“å†²åŒºã€ç®—æ³•é€»è¾‘å®Œå…¨è§£è€¦
- **å®Œæ•´æ¼”è¿›**ï¼š4 ä¸ªé˜¶æ®µï¼Œä»è¡¨æ ¼å‹åˆ°æ·±åº¦å¼ºåŒ–å­¦ä¹ 
- **GPU ä¼˜åŒ–**ï¼šå……åˆ†åˆ©ç”¨æ˜¾å¡è¿›è¡Œå¹¶è¡Œè®­ç»ƒ
- **ä¸°å¯Œçš„å¯è§†åŒ–**ï¼šæ¯ç§ç®—æ³•éƒ½æœ‰ä¸“é—¨çš„å¯è§†åŒ–æ–¹æ¡ˆ

### ğŸ“ é¡¹ç›®ç»“æ„

```
RL_Evolution/
â”œâ”€â”€ common/                     # é€šç”¨ç»„ä»¶
â”‚   â”œâ”€â”€ networks.py             # PyTorch ç½‘ç»œ
â”‚   â”œâ”€â”€ buffer.py               # ç¼“å†²åŒº
â”‚   â””â”€â”€ logger.py               # æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ stages/                     # å››ä¸ªæ¼”è¿›é˜¶æ®µ
â”‚   â”œâ”€â”€ stage1_tabular/         # Q-Learning
â”‚   â”œâ”€â”€ stage2_dqn/             # DQN
â”‚   â”œâ”€â”€ stage3_actor_critic/    # A2C
â”‚   â””â”€â”€ stage4_ppo/             # PPO
â”œâ”€â”€ utils/                      # å·¥å…·å‡½æ•°
â”œâ”€â”€ results/                    # è®­ç»ƒç»“æœ
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md
```

### ğŸ”§ ç¯å¢ƒè¦æ±‚

- **Python**: 3.7+
- **PyTorch**: 1.13.1+
- **CUDA**: 11.7+ (å¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿ)
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11, Linux, macOS

**æ¨èé…ç½®**:
- GPU: NVIDIA GTX 1050Ti æˆ–æ›´é«˜ (4GB+ æ˜¾å­˜)
- RAM: 8GB+

### ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# Stage 1: Q-Learning (FrozenLake-v1)
python stages/stage1_tabular/run.py

# Stage 2: DQN (CartPole-v1)
python stages/stage2_dqn/run.py

# Stage 3: A2C - ç»ˆæç‰ˆ (Acrobot-v1)
python stages/stage3_actor_critic/run_ultimate.py

# Stage 4: PPO (Acrobot-v1) - æ¨è
python stages/stage4_ppo/run.py
```

### ğŸ“Š ç®—æ³•æ¼”è¿›å¯¹æ¯”

| é˜¶æ®µ | ç®—æ³• | ç¯å¢ƒ | å¹³å‡å¥–åŠ± | è®­ç»ƒæ—¶é—´ |
|------|------|------|---------|---------|
| 1 | Q-Learning | FrozenLake | 100% æˆåŠŸç‡ | <1åˆ†é’Ÿ |
| 2 | DQN | CartPole | ~250 | ~5åˆ†é’Ÿ |
| 3 | A2C | Acrobot | ~-220 | ~30åˆ†é’Ÿ |
| 4 | **PPO** | Acrobot | **~-80** | ~20åˆ†é’Ÿ |

### ğŸ¨ å¯è§†åŒ–

æ¯ä¸ªé˜¶æ®µéƒ½ä¼šç”Ÿæˆè®­ç»ƒæ›²çº¿å’ŒæŒ‡æ ‡å›¾ï¼š
- `training_rewards.png`: å¥–åŠ±æ›²çº¿
- `training_metrics.png`: æŸå¤±å’ŒæŒ‡æ ‡æ›²çº¿

æŸ¥çœ‹ TensorBoard:
```bash
tensorboard --logdir=results/stage4/logs
```

### ğŸ› å¸¸è§é—®é¢˜

**PyTorch DLL é”™è¯¯**:
```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```

**Box2D å®‰è£…å¤±è´¥**:
```bash
conda install -c conda-forge box2d-py
```

---

<a name="english"></a>
## ğŸ‡ºğŸ‡¸ English Version

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.13+-red.svg)](https://pytorch.org/)
[![Gym](https://img.shields.io/badge/Gym-0.21+-green.svg)](https://gym.openai.com/)

This project is a **from-scratch** reinforcement learning tutorial demonstrating the complete evolution from simple Q-Learning to the advanced PPO algorithm.

### ğŸ¯ Features

- **Modular Design**: Environment interaction, network models, buffers, and algorithm logic are completely decoupled
- **Complete Evolution**: 4 stages, from tabular to deep reinforcement learning
- **GPU Optimized**: Fully utilizes GPU for parallel training
- **Rich Visualization**: Each algorithm has dedicated visualization

### ğŸ“ Project Structure

```
RL_Evolution/
â”œâ”€â”€ common/                     # Common components
â”‚   â”œâ”€â”€ networks.py             # PyTorch networks
â”‚   â”œâ”€â”€ buffer.py               # Replay and rollout buffers
â”‚   â””â”€â”€ logger.py               # Logging system
â”œâ”€â”€ stages/                     # Four evolution stages
â”‚   â”œâ”€â”€ stage1_tabular/         # Q-Learning
â”‚   â”œâ”€â”€ stage2_dqn/             # DQN
â”‚   â”œâ”€â”€ stage3_actor_critic/    # A2C
â”‚   â””â”€â”€ stage4_ppo/             # PPO
â”œâ”€â”€ utils/                      # Utilities
â”œâ”€â”€ results/                    # Training results
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md
```

### ğŸ”§ Requirements

- **Python**: 3.7+
- **PyTorch**: 1.13.1+
- **CUDA**: 11.7+ (optional, for GPU acceleration)
- **OS**: Windows 10/11, Linux, macOS

**Recommended**:
- GPU: NVIDIA GTX 1050Ti+ (4GB+ VRAM)
- RAM: 8GB+

### ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Stage 1: Q-Learning (FrozenLake-v1)
python stages/stage1_tabular/run.py

# Stage 2: DQN (CartPole-v1)
python stages/stage2_dqn/run.py

# Stage 3: A2C - Ultimate (Acrobot-v1)
python stages/stage3_actor_critic/run_ultimate.py

# Stage 4: PPO (Acrobot-v1) - Recommended
python stages/stage4_ppo/run.py
```

### ğŸ“Š Algorithm Comparison

| Stage | Algorithm | Environment | Avg Reward | Training Time |
|-------|-----------|-------------|------------|---------------|
| 1 | Q-Learning | FrozenLake | 100% success | <1 min |
| 2 | DQN | CartPole | ~250 | ~5 min |
| 3 | A2C | Acrobot | ~-220 | ~30 min |
| 4 | **PPO** | Acrobot | **~-80** | ~20 min |

### ğŸ¨ Visualization

Each stage generates training curves and metric plots:
- `training_rewards.png`: Reward curves
- `training_metrics.png`: Loss and metric curves

View TensorBoard:
```bash
tensorboard --logdir=results/stage4/logs
```

### ğŸ› Troubleshooting

**PyTorch DLL Error**:
```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```

**Box2D Installation Failed**:
```bash
conda install -c conda-forge box2d-py
```

---

<div align="center">
  <b>Happy Reinforcement Learning! ğŸš€</b><br>
  <b>å¼ºåŒ–å­¦ä¹ å¿«ä¹ï¼ğŸš€</b>
</div>
